#!/usr/bin/env python3
"""
Clean videos.json of malformed/quote-wrapped URLs.

Bad patterns:
  1. https://xamvn.*/[video]https%3A//...  →  forum-wrapped BBCode, DELETE
  2. https://cdn.save.moe/s11/X.mp4\n\nhttps%3A//...  →  strip suffix, KEEP base
  3. Any URL still containing %3A// or [video]/[/video] after strip → DELETE
"""

import re, json, sys

INPUT = "videos.json"
OUTPUT = "videos.json"
JS_OUT = "videos-data.js"


def clean_url(url):
    """Return cleaned URL or None if it should be deleted."""
    # Strip trailing encoded-duplicate garbage like \n\nhttps%3A//...
    url = re.split(r"\\n|%0A|\n", url)[0].strip()

    # Still contains BBCode-style wrapping or encoded :// → discard
    if "[video]" in url.lower() or "[/video]" in url.lower():
        return None
    if "[url=" in url.lower() or "[img]" in url.lower():
        return None
    if "%3A//" in url or "%3A%2F%2F" in url:
        return None

    # Must look like a direct http(s) mp4 URL with no spaces or brackets
    if not re.match(r'https?://[^\s\[\]<>"]+\.mp4$', url, re.I):
        return None

    return url


def main():
    with open(INPUT, encoding="utf-8") as f:
        data = json.load(f)

    total_before = sum(len(t.get("videos", [])) for t in data["threads"])
    threads_before = len(data["threads"])

    removed_bad = 0
    cleaned_suffix = 0
    empty_threads = 0

    clean_threads = []
    for thread in data["threads"]:
        clean_videos = []
        for url in thread.get("videos", []):
            # check for suffix-strippable
            if re.search(r"(\\n|%0A|\n)https?", url, re.I):
                cleaned_suffix += 1
            result = clean_url(url)
            if result is None:
                removed_bad += 1
            else:
                clean_videos.append(result)

        thread["videos"] = clean_videos
        if clean_videos:
            clean_threads.append(thread)
        else:
            empty_threads += 1

    data["threads"] = clean_threads
    data["total"] = sum(len(t["videos"]) for t in clean_threads)

    total_after = data["total"]

    print(f"Videos before : {total_before}")
    print(f"  Removed bad : {removed_bad}")
    print(f"  Suffix strip: {cleaned_suffix}")
    print(f"  Empty threads removed: {empty_threads}")
    print(f"Videos after  : {total_after}")
    print(f"Threads before: {threads_before}  →  after: {len(clean_threads)}")

    with open(OUTPUT, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    with open(JS_OUT, "w", encoding="utf-8") as f:
        f.write("// Auto-generated by crawl_videos.py — do not edit manually\n")
        f.write("window.VIDEOS_DATA = ")
        json.dump(data, f, ensure_ascii=False, separators=(",", ":"))
        f.write(";\n")

    print(f"\nSaved → {OUTPUT}  +  {JS_OUT}")


if __name__ == "__main__":
    main()
